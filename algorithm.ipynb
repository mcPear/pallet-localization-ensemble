{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "from joblib import load\n",
    "from dataset_io import *\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(image, split_channels, initial_scale, final_scale, scale=1.5):\n",
    "    original_w=image.shape[1]\n",
    "    curr_scale=initial_scale\n",
    "    while curr_scale>final_scale/scale:\n",
    "        w = int(original_w * curr_scale)\n",
    "        yield imutils.resize(image, width=w), [imutils.resize(ch, width=w) for ch in split_channels],curr_scale\n",
    "        curr_scale/=scale\n",
    "        \n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (120,24)\n",
    "DS_min_winH_m=41\n",
    "DS_max_winH_m=287\n",
    "initial_scale=winH/DS_min_winH_m\n",
    "final_scale=winH/DS_max_winH_m\n",
    "\n",
    "clf = load('rand_forest_clf.joblib') \n",
    "clf.set_params(n_jobs=-1)\n",
    "\n",
    "def show(img, x, y, winW, winH, positives=[]):\n",
    "    clone = img.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (255, 255, 255), 2)\n",
    "    for p in positives:\n",
    "        x,y=p\n",
    "        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Window\", clone)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def global_predict():\n",
    "    global glob_X, glob_Y\n",
    "    if len(glob_X)!=0:\n",
    "        pred=[p[1] for p in clf.predict_proba(glob_X)]\n",
    "        if len(glob_Y)==0:\n",
    "            glob_Y=pred\n",
    "        else:\n",
    "            glob_Y=np.concatenate((glob_Y,pred))\n",
    "        glob_X=[]\n",
    "    \n",
    "def predict(filename, scene_name, label_resolution, rects):\n",
    "    global glob_X,glob_IDX,glob_IT,glob_DUMP_IT\n",
    "    \n",
    "    image=imread_resized(scene_name, filename, label_resolution)\n",
    "    split_channels=read_split_channels(scene_name, filename)\n",
    "    X=[]\n",
    "    for resized_img, resized_split_ch, scale in pyramid(image, split_channels, initial_scale, final_scale, scale=1.15):\n",
    "#         draw_preds=[]\n",
    "        resized_ch=np.dstack(resized_split_ch)\n",
    "        for (x, y, window) in sliding_window(resized_img, stepSize=4, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            channels_window=resized_ch[y:y + winH, x:x + winW]\n",
    "            features=channels_window.flatten()\n",
    "            glob_X.append(features)\n",
    "            glob_IDX.append([scene_name, filename, scale, (x,y)])\n",
    "#             if clf.predict([features]):\n",
    "#                 draw_preds.append((x, y))\n",
    "            #show(resized_img, x, y, winW, winH, draw_preds)\n",
    "    glob_IT+=1\n",
    "    if glob_IT==glob_DUMP_IT:\n",
    "        global_predict()\n",
    "        glob_IT=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:12<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147040 2147040 0\n",
      "(2147040, 4) (2147040, 1) (2147040, 5)\n"
     ]
    }
   ],
   "source": [
    "glob_X=[]\n",
    "glob_IDX=[]\n",
    "glob_Y=[]\n",
    "glob_IT=0\n",
    "glob_DUMP_IT=1 # adjust manually to RAM\n",
    "\n",
    "[predict(*row) for row in tqdm([row for row in walk_dataset() if row[1]==\"blue_1\"])]# and row[0]==\"IMG_20200229_075416.jpg\"])]\n",
    "global_predict()\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "np.save(\"run/sliding_window_IDX_\"+date_time,glob_IDX)\n",
    "np.save(\"run/sliding_window_Y_\"+date_time,glob_Y)\n",
    "print(len(glob_IDX), len(glob_Y),len(glob_X))\n",
    "\n",
    "#glob_IDX=np.load(\"run/sliding_window_IDX_07-04-2020_17:59:14.npy\",allow_pickle=True)\n",
    "#glob_Y=np.load(\"run/sliding_window_Y_07-04-2020_17:59:14.npy\",allow_pickle=True)\n",
    "glob_Y=np.array([[e] for e in glob_Y])\n",
    "RES=np.append(glob_IDX, glob_Y, 1)\n",
    "print(np.array(glob_IDX).shape, glob_Y.shape, RES.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_20200229_075347.jpg\n",
      "IMG_20200229_075348.jpg\n",
      "IMG_20200229_075349.jpg\n",
      "IMG_20200229_075350.jpg\n",
      "IMG_20200229_075353.jpg\n",
      "IMG_20200229_075356.jpg\n",
      "IMG_20200229_075358.jpg\n",
      "IMG_20200229_075400.jpg\n",
      "IMG_20200229_075401.jpg\n",
      "IMG_20200229_075405.jpg\n",
      "IMG_20200229_075406.jpg\n",
      "IMG_20200229_075407.jpg\n",
      "IMG_20200229_075408.jpg\n",
      "IMG_20200229_075410.jpg\n",
      "IMG_20200229_075411.jpg\n",
      "IMG_20200229_075413.jpg\n",
      "IMG_20200229_075414.jpg\n",
      "IMG_20200229_075416.jpg\n",
      "IMG_20200229_075417.jpg\n",
      "IMG_20200229_075419.jpg\n",
      "IMG_20200229_075426.jpg\n",
      "IMG_20200229_075427.jpg\n",
      "IMG_20200229_075428.jpg\n",
      "IMG_20200229_075430.jpg\n",
      "IMG_20200229_075431.jpg\n",
      "IMG_20200229_075434.jpg\n",
      "IMG_20200229_075435.jpg\n",
      "IMG_20200229_075436.jpg\n",
      "IMG_20200229_075437.jpg\n",
      "IMG_20200229_075438.jpg\n",
      "IMG_20200229_075439.jpg\n",
      "IMG_20200229_075440.jpg\n",
      "IMG_20200229_075442.jpg\n",
      "IMG_20200229_075443.jpg\n",
      "IMG_20200229_075449.jpg\n",
      "IMG_20200229_075450.jpg\n",
      "IMG_20200229_075452.jpg\n",
      "IMG_20200229_075453.jpg\n",
      "IMG_20200229_075454.jpg\n",
      "IMG_20200229_075457.jpg\n",
      "IMG_20200229_075458.jpg\n",
      "IMG_20200229_075500.jpg\n",
      "IMG_20200229_075501.jpg\n",
      "IMG_20200229_075502.jpg\n",
      "IMG_20200229_075504.jpg\n",
      "IMG_20200229_075505.jpg\n",
      "IMG_20200229_075506.jpg\n",
      "IMG_20200229_075507.jpg\n",
      "Mean overlapping:  0.6901846882747412\n"
     ]
    }
   ],
   "source": [
    "def area(rect):\n",
    "    ((x,y),(x2,y2))=rect\n",
    "    return (x2-x)*(y2-y)\n",
    "\n",
    "def calc_overlapping(a,b):\n",
    "    dx = min(a[1][0], b[1][0]) - max(a[0][0], b[0][0])\n",
    "    dy = min(a[1][1], b[1][1]) - max(a[0][1], b[0][1])\n",
    "    max_area=np.max([area(a), area(b)])\n",
    "    overlap_area=dx*dy\n",
    "    return overlap_area/max_area if ((dx>=0) and (dy>=0)) else 0\n",
    "\n",
    "def calc_overlappings(rects, pred_rects):\n",
    "    global glob_overlappings    \n",
    "    overlappings=[np.max([calc_overlapping(pred_rect,rect) for pred_rect in pred_rects]) for rect in rects]\n",
    "    glob_overlappings.extend(overlappings)\n",
    "\n",
    "def scale_many(vals, scale):\n",
    "    return [int(val/scale) for val in vals]\n",
    "\n",
    "def draw_predicted_rectangles(filename, scene_name, label_resolution, rects):\n",
    "    img=imread_resized(scene_name, filename, label_resolution)\n",
    "    file_res=RES[np.where((RES[:,0] == scene_name) * (RES[:,1] == filename))]\n",
    "    \n",
    "    n_rects=len(rects)\n",
    "    max_rows=file_res[np.argsort(file_res[:,4])[-n_rects:]]\n",
    "    pred_rects=[]\n",
    "    rects=[add_margin(correct_rect_ratio(rect)) for rect in rects]\n",
    "    for max_row in max_rows:\n",
    "        [scene_name, filename, scale, (x,y), pred]=max_row\n",
    "        [x,y,winW_s,winH_s]=scale_many([x,y,winW,winH], scale)\n",
    "        cv2.rectangle(img, (x,y), (x + winW_s, y + winH_s), (0, 255, 0), 2)\n",
    "        pred_rects.append(((x,y),(x+winW_s, y+winH_s)))\n",
    "    for rect in rects:\n",
    "        ((x,y),(x2,y2))=rect\n",
    "        cv2.rectangle(img, (x,y), (x2,y2), (255, 0, 0), 2)\n",
    "        \n",
    "#     for row in file_res:\n",
    "#         [scene_name, filename, scale, (x,y), pred]=row\n",
    "#         [x,y,winW_s,winH_s]=scale_many([x,y,winW,winH], scale)\n",
    "#         #print(winH_s)\n",
    "#         if pred>0.9:\n",
    "#             cv2.rectangle(img, (x,y), (x + winW_s, y + winH_s), (0, 255, 0), 2)\n",
    "    save_image(img, scene_name, filename, \"predicted_labels\")\n",
    "    calc_overlappings(rects, pred_rects)\n",
    "\n",
    "glob_overlappings=[]\n",
    "[draw_predicted_rectangles(*row) for row in walk_dataset() if row[1]==\"blue_1\"]# and row[0]==\"IMG_20200229_075416.jpg\"]\n",
    "print(\"Mean overlapping: \",np.mean(glob_overlappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window only - 1.36s\n",
    "# features only - 1.47s\n",
    "# classify per image - 2.82s\n",
    "# classify per scale - 8.47s\n",
    "# dsiplay, features only - 52.64s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
