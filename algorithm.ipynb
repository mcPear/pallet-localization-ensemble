{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "from joblib import load\n",
    "from dataset_io import *\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(image, split_channels, initial_scale, final_scale, scale=1.5):\n",
    "    original_w=image.shape[1]\n",
    "    curr_scale=initial_scale\n",
    "    while curr_scale>final_scale/scale:\n",
    "        w = int(original_w * curr_scale)\n",
    "        yield imutils.resize(image, width=w), [imutils.resize(ch, width=w) for ch in split_channels],curr_scale\n",
    "        curr_scale/=scale\n",
    "        \n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(rect):\n",
    "    ((x,y),(x2,y2))=rect\n",
    "    return (x2-x)*(y2-y)\n",
    "\n",
    "def calc_overlapping(a,b, fun):\n",
    "    dx = min(a[1][0], b[1][0]) - max(a[0][0], b[0][0])\n",
    "    dy = min(a[1][1], b[1][1]) - max(a[0][1], b[0][1])\n",
    "    max_area=fun([area(a), area(b)])\n",
    "    overlap_area=dx*dy\n",
    "    return overlap_area/max_area if ((dx>=0) and (dy>=0)) else 0\n",
    "\n",
    "def scale_many(vals, scale):\n",
    "    return [int(val/scale) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (120,24)\n",
    "DS_min_winH_m=41\n",
    "DS_max_winH_m=287\n",
    "initial_scale=winH/DS_min_winH_m\n",
    "final_scale=winH/DS_max_winH_m\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "clf = load('rand_forest_clf.joblib') \n",
    "clf.set_params(n_jobs=-1)\n",
    "\n",
    "def show(img, x, y, winW, winH, positives=[]):\n",
    "    clone = img.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (255, 255, 255), 2)\n",
    "    for p in positives:\n",
    "        x,y=p\n",
    "        cv2.rectangle(clone, (x, y), (x + winW, y + winH), (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Window\", clone)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def image_predict(X,IDX,rects_count):\n",
    "    global glob_RES\n",
    "    if len(X)!=0 and rects_count>0:\n",
    "        pred=np.array([p[1] for p in clf.predict_proba(X)]) # weź tylko te powyżej 0.9, w IDX też\n",
    "        max_pred_ids=[]\n",
    "        max_preds=[]\n",
    "        max_pred_IDXs=[]\n",
    "        for i in range(rects_count):\n",
    "            print(\"pred/IDX\", pred.shape, IDX.shape)\n",
    "            max_pred_id=np.argmax(pred)\n",
    "            max_pred=pred[max_pred_id]\n",
    "            print(\"max_pred\", max_pred)\n",
    "            max_preds.append(max_pred)\n",
    "            max_pred_IDX=IDX[max_pred_id]\n",
    "            max_pred_IDXs.append(max_pred_IDX)\n",
    "            \n",
    "            [scene_name, filename, scale, (x,y)]=max_pred_IDX\n",
    "            [xs,ys,ws,hs]=scale_many([x,y,winW,winH], scale)\n",
    "            \n",
    "            def not_within(row, x, y, h, w):\n",
    "                a=((x,y),(x+w,y+h))\n",
    "                \n",
    "                [scene_name, filename, scale, (rx,ry)]=row\n",
    "                [rx,ry,rw,rh]=scale_many([rx,ry,winW,winH], scale)\n",
    "                b=((rx,ry),(rx+rw,ry+rh))\n",
    "                \n",
    "                return calc_overlapping(a,b,np.min) < 0.5\n",
    "\n",
    "            not_within_bools = np.array([not_within(row, xs, ys, hs, ws) for row in IDX])\n",
    "            pred=pred[not_within_bools]\n",
    "            IDX=IDX[not_within_bools]\n",
    "        \n",
    "        max_preds=np.array([[e] for e in max_preds])\n",
    "        res=np.append(max_pred_IDXs, max_preds, 1)\n",
    "        \n",
    "        glob_RES=np.vstack([glob_RES,res])\n",
    "    \n",
    "def predict(filename, scene_name, label_resolution, rects):\n",
    "    X=[]\n",
    "    IDX=np.empty((0,4), object)\n",
    "    \n",
    "    image=imread_resized(scene_name, filename, label_resolution)\n",
    "    split_channels=read_split_channels(scene_name, filename)\n",
    "    for resized_img, resized_split_ch, scale in pyramid(image, split_channels, initial_scale, final_scale, scale=1.15):\n",
    "        resized_ch=np.dstack(resized_split_ch)\n",
    "        for (x, y, window) in sliding_window(resized_img, stepSize=4, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            channels_window=resized_ch[y:y + winH, x:x + winW]\n",
    "            features=channels_window.flatten()\n",
    "            X.append(features)\n",
    "            #IDX.append([scene_name, filename, scale, (x,y)])\n",
    "            row=[scene_name, filename, scale, (x,y)]\n",
    "            IDX=np.vstack([IDX, row])\n",
    "    image_predict(X,IDX, len(rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glob_RES=np.empty((0,5), object)\n",
    "\n",
    "glob_DATETIME = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "def predict_all():\n",
    "    [predict(*row) for row in tqdm([row for row in walk_dataset() if row[1]==\"warehouse_1\"])]# and row[0]==\"r_1_0.jpg\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/114 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (71171,) (71171, 4)\n",
      "max_pred 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/114 [00:23<44:47, 23.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (71283,) (71283, 4)\n",
      "max_pred 0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/114 [00:47<44:17, 23.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.9921875\n",
      "pred/IDX (71171,) (71171, 4)\n",
      "max_pred 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 13/114 [04:30<33:11, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (71171,) (71171, 4)\n",
      "max_pred 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 18/114 [06:16<32:41, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (71171,) (71171, 4)\n",
      "max_pred 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 19/114 [06:40<33:50, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (70583,) (70583, 4)\n",
      "max_pred 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 20/114 [07:04<34:37, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.984375\n",
      "pred/IDX (69504,) (69504, 4)\n",
      "max_pred 0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 21/114 [07:27<34:38, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 22/114 [07:49<34:20, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.9921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 23/114 [08:11<33:49, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.9765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 24/114 [08:34<33:26, 22.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 25/114 [08:57<33:28, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 26/114 [09:20<33:13, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 1.0\n",
      "pred/IDX (71283,) (71283, 4)\n",
      "max_pred 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▎       | 27/114 [09:44<33:34, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred/IDX (74066,) (74066, 4)\n",
      "max_pred 0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▍       | 28/114 [10:09<34:06, 23.80s/it]"
     ]
    }
   ],
   "source": [
    "cProfile.runctx(\n",
    "            'predict_all()',\n",
    "            globals(),\n",
    "            locals(),\n",
    "            'myProfilingFile.pstats'\n",
    "        )\n",
    "os.chdir(PROJECT_PATH)\n",
    "!python3 /usr/local/lib/python3.6/dist-packages/gprof2dot.py -f pstats myProfilingFile.pstats | dot -Tpng -o image_output.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_overlappings(rects, pred_rects):\n",
    "    global glob_overlappings    \n",
    "    overlappings=[np.max([calc_overlapping(pred_rect,rect, np.max) for pred_rect in pred_rects]) for rect in rects]\n",
    "    glob_overlappings.extend(overlappings)\n",
    "\n",
    "def draw_predicted_rectangles(filename, scene_name, label_resolution, rects):\n",
    "    global glob_RES\n",
    "    \n",
    "    img=imread_resized(scene_name, filename, label_resolution)\n",
    "    img_rows=glob_RES[np.where((glob_RES[:,0] == scene_name) * (glob_RES[:,1] == filename))]\n",
    "    \n",
    "    #n_rects=len(rects)\n",
    "    #max_rows=file_res[np.argsort(file_res[:,4])[-n_rects:]]\n",
    "    pred_rects=[]\n",
    "    rects=[add_margin(correct_rect_ratio(rect)) for rect in rects]\n",
    "    for max_row in img_rows:\n",
    "        [scene_name, filename, scale, (x,y), pred]=max_row\n",
    "        [x,y,winW_s,winH_s]=scale_many([x,y,winW,winH], scale)\n",
    "        cv2.rectangle(img, (x,y), (x + winW_s, y + winH_s), (0, 255, 0), 2)\n",
    "        pred_rects.append(((x,y),(x+winW_s, y+winH_s)))\n",
    "    for rect in rects: \n",
    "        ((x,y),(x2,y2))=rect\n",
    "        cv2.rectangle(img, (x,y), (x2,y2), (255, 0, 0), 2)\n",
    "        \n",
    "#     for row in file_res:\n",
    "#         [scene_name, filename, scale, (x,y), pred]=row\n",
    "#         [x,y,winW_s,winH_s]=scale_many([x,y,winW,winH], scale)\n",
    "#         #print(winH_s)\n",
    "#         if pred>0.9:\n",
    "#             cv2.rectangle(img, (x,y), (x + winW_s, y + winH_s), (0, 255, 0), 2)\n",
    "    save_image(img, scene_name, filename, \"predicted_labels\")\n",
    "    calc_overlappings(rects, pred_rects)\n",
    "\n",
    "glob_overlappings=[]\n",
    "[draw_predicted_rectangles(*row) for row in tqdm(walk_dataset()) if row[1]==\"warehouse_1\"]# and row[0]==\"r_1_0.jpg\"]\n",
    "print(\"Mean overlapping: \",np.mean(glob_overlappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window only - 1.36s\n",
    "# features only - 1.47s\n",
    "# classify per image - 2.82s\n",
    "# classify per scale - 8.47s\n",
    "# dsiplay, features only - 52.64s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
