{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "import imutils\n",
    "from joblib import load\n",
    "from dataset_io import *\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from profiler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(image, split_channels, initial_scale, final_scale, scale):\n",
    "    original_w=image.shape[1]\n",
    "    curr_scale=initial_scale\n",
    "    while curr_scale>final_scale/scale:\n",
    "        w = int(original_w * curr_scale)\n",
    "        yield imutils.resize(image, width=w), [imutils.resize(ch, width=w) for ch in split_channels],curr_scale\n",
    "        curr_scale/=scale\n",
    "        \n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(rect):\n",
    "    ((x,y),(x2,y2))=rect\n",
    "    return (x2-x)*(y2-y)\n",
    "\n",
    "def calc_overlapping(a,b,method):\n",
    "    dx = min(a[1][0], b[1][0]) - max(a[0][0], b[0][0])\n",
    "    dy = min(a[1][1], b[1][1]) - max(a[0][1], b[0][1])\n",
    "    basic_area=method([area(a), area(b)])\n",
    "    overlap_area=dx*dy\n",
    "    is_overlapping=((dx>=0) and (dy>=0))\n",
    "    overlapping_ratio=overlap_area/basic_area\n",
    "    \n",
    "    return overlapping_ratio if is_overlapping else 0\n",
    "\n",
    "def scale_many(vals, scale):\n",
    "    return [int(val/scale) for val in vals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=128,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(PROJECT_PATH)\n",
    "clf = load('rand_forest_clf.joblib') \n",
    "clf.set_params(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(winW, winH) = (120,24)\n",
    "channels_no=8\n",
    "DS_min_winH_m=41\n",
    "DS_max_winH_m=287\n",
    "initial_scale=winH/DS_min_winH_m\n",
    "final_scale=winH/DS_max_winH_m\n",
    "RESIZING_SCALE=1.15\n",
    "MAX_PRED_OVERLAPPING=0.5\n",
    "MIN_PRED=0.8\n",
    "WHITE=(255, 255, 255)\n",
    "DRAW_BORDER=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, x, y, winW, winH, positives=[]):\n",
    "    clone = img.copy()\n",
    "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), WHITE, DRAW_BORDER)\n",
    "    for p in positives:\n",
    "        x,y=p\n",
    "        cv2.rectangle(clone, (x, y), (x + winW, y + winH), WHITE, DRAW_BORDER)\n",
    "    cv2.imshow(\"Window\", clone)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def pred_overlapping(row, scaled_rect):\n",
    "    x,y,h,w = scaled_rect\n",
    "    a = ((x,y),(x+w,y+h))\n",
    "    [scene_name, filename, scale, (rx,ry)] = row\n",
    "    [rx,ry,rw,rh] = scale_many([rx,ry,winW,winH], scale)\n",
    "    b = ((rx,ry),(rx+rw,ry+rh))\n",
    "\n",
    "    return calc_overlapping(a,b,np.min)\n",
    "    \n",
    "def image_predict(X,IDX,rects_count):\n",
    "    global glob_RES\n",
    "    if len(X)!=0 and rects_count>0:\n",
    "        pred=np.array([p[1] for p in clf.predict_proba(X)])\n",
    "        greater_than_09=pred > MIN_PRED\n",
    "        pred=pred[greater_than_09]\n",
    "        IDX=IDX[greater_than_09]\n",
    "        max_pred_ids=[]\n",
    "        max_preds=[]\n",
    "        max_pred_IDXs=[]\n",
    "        for i in range(rects_count):\n",
    "            if len(pred) >0:\n",
    "                max_pred_id=np.argmax(pred)\n",
    "                max_pred=pred[max_pred_id]\n",
    "                max_preds.append(max_pred)\n",
    "                max_pred_IDX=IDX[max_pred_id]\n",
    "                max_pred_IDXs.append(max_pred_IDX)\n",
    "\n",
    "                [scene_name, filename, scale, (x,y)]=max_pred_IDX\n",
    "                scaled_rect=scale_many([x,y,winW,winH], scale)\n",
    "\n",
    "                not_within_bools = np.array([pred_overlapping(row, scaled_rect) < MAX_PRED_OVERLAPPING for row in IDX])\n",
    "                pred=pred[not_within_bools]\n",
    "                IDX=IDX[not_within_bools]\n",
    "            else:\n",
    "                print(\"No more predictions with prob > 0.8\")\n",
    "        if len(max_preds)>0:\n",
    "            max_preds=np.array([[e] for e in max_preds])\n",
    "            res=np.append(max_pred_IDXs, max_preds, 1)\n",
    "            glob_RES=np.vstack([glob_RES,res])\n",
    "    \n",
    "def predict(filename, scene_name, label_resolution, rects):\n",
    "    X=[]\n",
    "    IDX=[]\n",
    "    \n",
    "    image=imread_resized(scene_name, filename, label_resolution)\n",
    "    split_channels=read_split_channels(scene_name, filename)\n",
    "    for resized_img, resized_split_ch, scale in pyramid(image, split_channels, initial_scale, final_scale, scale=RESIZING_SCALE):\n",
    "        resized_ch=np.dstack(resized_split_ch)\n",
    "        for (x, y, window) in sliding_window(resized_img, stepSize=4, windowSize=(winW, winH)):\n",
    "            # if the window does not meet our desired window size, ignore it\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            channels_window=resized_ch[y:y + winH, x:x + winW] #czy tu są floaty? niech dataset_prepr zwraca int16 !!! inne grube zmienne też sprawdź\n",
    "            X.append(channels_window)\n",
    "            row=[scene_name, filename, scale, (x,y)]\n",
    "            IDX.append(row)\n",
    "    X=np.reshape(X,(len(X),winW*winH*channels_no)) #cupy does not help\n",
    "    image_predict(X,np.array(IDX), len(rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2092 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_split_channels() missing 1 required positional argument: 'output_dir_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-93a7b4ec9939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# if row[1]==\"warehouse_1\"])]# and row[0]==\"r_1_0.jpg\"])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprofiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_all()'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/pallet-recogntion-gpu/profiler.py\u001b[0m in \u001b[0;36mprofiled\u001b[0;34m(expr, globalz, localz)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mglobalz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mlocalz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;34m'/home/maciej/repos/pallet-recogntion-gpu/profiler_result.pstats'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         )\n\u001b[1;32m     11\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 /usr/local/lib/python3.6/dist-packages/gprof2dot.py -f pstats /home/maciej/repos/pallet-recogntion-gpu/profiler_result.pstats | dot -Tpng -o /home/maciej/repos/pallet-recogntion-gpu/profiler_result.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(statement, globals, locals, filename, sort)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     return _pyprofile._Utils(Profile).runctx(statement, globals, locals,\n\u001b[0;32m---> 20\u001b[0;31m                                              filename, sort)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pyprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/profile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, statement, globals, locals, filename, sort)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-93a7b4ec9939>\u001b[0m in \u001b[0;36mpredict_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# if row[1]==\"warehouse_1\"])]# and row[0]==\"r_1_0.jpg\"])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprofiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_all()'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-93a7b4ec9939>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# if row[1]==\"warehouse_1\"])]# and row[0]==\"r_1_0.jpg\"])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprofiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_all()'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c44f79e5e43c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(filename, scene_name, label_resolution, rects)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimread_resized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_resolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0msplit_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_split_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresized_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized_split_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpyramid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESIZING_SCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mresized_ch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_split_ch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_split_channels() missing 1 required positional argument: 'output_dir_name'"
     ]
    }
   ],
   "source": [
    "glob_RES=np.empty((0,5), object)\n",
    "\n",
    "glob_DATETIME = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "def predict_all():\n",
    "    [predict(*row) for row in tqdm([row for row in walk_dataset()])]# if row[1]==\"warehouse_1\"])]# and row[0]==\"r_1_0.jpg\"])]\n",
    "    \n",
    "profiled('predict_all()', globals(), locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_overlappings(rects, pred_rects):\n",
    "    global glob_overlappings    \n",
    "    overlappings=[(np.max([calc_overlapping(pred_rect,rect, np.max) for pred_rect in pred_rects]) if len(pred_rects) > 0 else 0) for rect in rects]\n",
    "    glob_overlappings.extend(overlappings)\n",
    "\n",
    "def draw_predicted_rectangles(filename, scene_name, label_resolution, rects):\n",
    "    global glob_RES\n",
    "    \n",
    "    img=imread_resized(scene_name, filename, label_resolution)\n",
    "    img_rows=glob_RES[np.where((glob_RES[:,0] == scene_name) * (glob_RES[:,1] == filename))]\n",
    "    \n",
    "    pred_rects=[]\n",
    "    rects=[add_margin(correct_rect_ratio(rect)) for rect in rects]\n",
    "    for max_row in img_rows:\n",
    "        [scene_name, filename, scale, (x,y), pred]=max_row\n",
    "        [x,y,winW_s,winH_s]=scale_many([x,y,winW,winH], scale)\n",
    "        cv2.rectangle(img, (x,y), (x + winW_s, y + winH_s), (0, 255, 0), 2)\n",
    "        pred_rects.append(((x,y),(x+winW_s, y+winH_s)))\n",
    "    for rect in rects: \n",
    "        ((x,y),(x2,y2))=rect\n",
    "        cv2.rectangle(img, (x,y), (x2,y2), (255, 0, 0), 2)\n",
    "    \n",
    "    save_image(img, scene_name, filename, \"predicted_labels\")\n",
    "    calc_overlappings(rects, pred_rects)\n",
    "\n",
    "glob_overlappings=[]\n",
    "[draw_predicted_rectangles(*row) for row in tqdm(walk_dataset())]# if row[1]==\"warehouse_1\"]# and row[0]==\"r_1_0.jpg\"]\n",
    "print(\"Mean overlapping: \",np.mean(glob_overlappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_pred=0.8 : overlap = 0.623"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
